---
slug: the-story-of-the-paperclip-maximiser-and-responsible-ai
publishDate: 2021-03-12T06:18:15Z
author: Ranjani Mani
title: The story of the paperclip maximiser and responsible AI 
excerpt: 𝗖𝗮𝗻, 𝗯𝘂𝘁 𝗜 𝗱𝗼𝗻’𝘁 𝗯𝗲𝗹𝗶𝗲𝘃𝗲 𝘄𝗲 𝘀𝗵𝗼𝘂𝗹𝗱 And that statement is quite relevant in the space of 𝗥𝗲𝘀𝗽𝗼𝗻𝘀𝗶𝗯𝗹𝗲 𝗔𝗜. Humans are the ones who decide what the machine should be maximizing. Are we taking a human-centered approach and understanding the limitations of the data set and model? Have you heard of Nick Bostrom’s famous paperclip  ... 
category: 21
---

𝗖𝗮𝗻, 𝗯𝘂𝘁 𝗜 𝗱𝗼𝗻’𝘁 𝗯𝗲𝗹𝗶𝗲𝘃𝗲 𝘄𝗲 𝘀𝗵𝗼𝘂𝗹𝗱

And that statement is quite relevant in the space of 𝗥𝗲𝘀𝗽𝗼𝗻𝘀𝗶𝗯𝗹𝗲 𝗔𝗜.

Humans are the ones who decide what the machine should be maximizing.

Are we taking a human-centered approach and understanding the limitations of the data set and model?

Have you heard of Nick Bostrom’s famous paperclip maximiser example that illustrates this?

“A Paperclip Maximizer is a hypothetical artificial intelligence \[AGI\]

It’s utility function values maximizing the number of paperclips in the universe.

The paperclip maximizer is an thought experiment showing how an AGI, even one designed competently and without malice, could pose existential threats.

It would innovate better and better techniques to maximize the number of paperclips.

At some point, it might transform “first all of earth and then increasing portions of space into paperclip manufacturing facilities”.

For those who are interested I have the link to Nick Bostrom’s paper on Ethical Issues in Advanced Artificial Intelligence below

Here is Nick Bostrom’s paper on Ethical issues in advanced AI – <https://nickbostrom.com/ethics/ai.html>

https://hackernoon.com/the-parable-of-the-paperclip-maximizer-3ed4cccc669a

Do you have resources/papers you recommend around ethical AI?

[#reviewswithranjani](https://www.linkedin.com/feed/hashtag/?keywords=reviewswithranjani&highlightedUpdateUrns=urn%3Ali%3Aactivity%3A6776019523859570688)